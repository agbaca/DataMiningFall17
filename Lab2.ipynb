{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2 - Vehicles with over 100K Kilometers.\n",
    "\n",
    "    Scott Gozdzialski\n",
    "    Adam Baca\n",
    "    Zoheb Allam\n",
    "    Ethan Graham\n",
    "    \n",
    "    The data can be found https://www.kaggle.com/mirosval/personal-cars-classifieds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Data Preparation Part 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are roughly 3,5 Million rows and the following columns:\n",
    "\n",
    "- maker - The manufacturer of the vehicle\n",
    "- model - The distinct model of the vehicle\n",
    "- mileage - in KM (our Response variable)\n",
    "- manufacture_year\n",
    "- engine_displacement - in cc\n",
    "- engine_power - in kW\n",
    "- body_type - Coupe, van, sedan, etc.\n",
    "- color_slug - main color of the vehicle\n",
    "- stk_year - year of the last emission control\n",
    "- transmission - automatic or manual\n",
    "- door_count\n",
    "- seat_count\n",
    "- fuel_type - gasoline, diesel, cng, lpg, electric\n",
    "- date_created - when the ad was scraped\n",
    "- date_last_seen - when the ad was last seen. Our policy was to remove all ads older than 60 days\n",
    "- price_eur - list price converted to EUR\n",
    "\n",
    "The first step is to download the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Import the file of 3.5 Million records we will parse it down to 81000 usable records\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from __future__ import print_function\n",
    "path = \"~\\\\Desktop\\\\Cars.csv\"\n",
    "\n",
    "df = pd.read_csv(path,sep = \",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we are going to have to clean the data.  As can be seen below most of the data is object type wich will not work for our classification models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3552912 entries, 0 to 3552911\n",
      "Data columns (total 16 columns):\n",
      "maker                  object\n",
      "model                  object\n",
      "mileage                float64\n",
      "manufacture_year       float64\n",
      "engine_displacement    float64\n",
      "engine_power           float64\n",
      "body_type              object\n",
      "color_slug             object\n",
      "stk_year               object\n",
      "transmission           object\n",
      "door_count             object\n",
      "seat_count             object\n",
      "fuel_type              object\n",
      "date_created           object\n",
      "date_last_seen         object\n",
      "price_eur              float64\n",
      "dtypes: float64(5), object(11)\n",
      "memory usage: 433.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we change the date the ad was created and the date it was removed to a interger of the number of days the ad ran. then we drop the columns we will not be using. Stk-year is very close to model year, model takes up to much memory seperate and is unworkable.  Finally we will drop all the rows with NAs.  With 3.5 rows we have plenty to use after removing them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Convert the date varibles into a delta between and type int\n",
    "df.date_created = pd.to_datetime(df['date_created'])\n",
    "df.date_last_seen = pd.to_datetime(df['date_last_seen'])\n",
    "df['total_days'] = df['date_last_seen'] - df['date_created']\n",
    "df.total_days = df['total_days'].dt.days.astype(int)\n",
    "\n",
    "df.drop(['stk_year','model','date_created','date_last_seen'], axis=1, inplace=True)\n",
    "\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we convert door count and seat count to ints, and remove eronious information.  There are no vehicles with a 10cc engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.door_count = df.door_count.replace('None','0')\n",
    "df.door_count = df.door_count.astype(int)\n",
    "df.seat_count = df.door_count.replace('None','0')\n",
    "df.seat_count = df.door_count.astype(int)\n",
    "\n",
    "df = df.sort_values('engine_displacement', ascending=False)\n",
    "df = df[:82088]\n",
    "\n",
    "df = df.sort_values('engine_power', ascending=False)\n",
    "df = df[:81500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we OneHotEncode maker, body type,color slug, and fuel type. We turn Transmision to binary (1,0) variable. Finally we remove the columns that we OneHotEncoded.  We also make a back up dataframe incase we make a mistake we can go backto this point without rerunning everything above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp_df = pd.get_dummies(df.maker,prefix='Maker')\n",
    "df = pd.concat((df,tmp_df),axis=1) # add back into the dataframe\n",
    "\n",
    "tmp_df = pd.get_dummies(df.body_type,prefix='Body type')\n",
    "df = pd.concat((df,tmp_df),axis=1) # add back into the dataframe\n",
    "\n",
    "tmp_df = pd.get_dummies(df.color_slug,prefix='Color')\n",
    "df = pd.concat((df,tmp_df),axis=1) # add back into the dataframe\n",
    "\n",
    "tmp_df = pd.get_dummies(df.fuel_type,prefix='Fuel')\n",
    "df = pd.concat((df,tmp_df),axis=1) # add back into the dataframe\n",
    "\n",
    "df['manual'] = df.transmission=='man' \n",
    "df.manual = df.manual.astype(np.int)\n",
    "\n",
    "df.drop(['body_type','color_slug','fuel_type','maker','transmission'], axis= 1, inplace = True)\n",
    "\n",
    "df_backup = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 81500 entries, 3215366 to 3153910\n",
      "Data columns (total 82 columns):\n",
      "manufacture_year          81500 non-null float64\n",
      "engine_displacement       81500 non-null float64\n",
      "engine_power              81500 non-null float64\n",
      "door_count                81500 non-null int32\n",
      "seat_count                81500 non-null int32\n",
      "price_eur                 81500 non-null float64\n",
      "total_days                81500 non-null int32\n",
      "Maker_alfa-romeo          81500 non-null uint8\n",
      "Maker_aston-martin        81500 non-null uint8\n",
      "Maker_audi                81500 non-null uint8\n",
      "Maker_bentley             81500 non-null uint8\n",
      "Maker_bmw                 81500 non-null uint8\n",
      "Maker_chevrolet           81500 non-null uint8\n",
      "Maker_chrysler            81500 non-null uint8\n",
      "Maker_citroen             81500 non-null uint8\n",
      "Maker_dacia               81500 non-null uint8\n",
      "Maker_dodge               81500 non-null uint8\n",
      "Maker_fiat                81500 non-null uint8\n",
      "Maker_ford                81500 non-null uint8\n",
      "Maker_honda               81500 non-null uint8\n",
      "Maker_hummer              81500 non-null uint8\n",
      "Maker_hyundai             81500 non-null uint8\n",
      "Maker_infinity            81500 non-null uint8\n",
      "Maker_isuzu               81500 non-null uint8\n",
      "Maker_jaguar              81500 non-null uint8\n",
      "Maker_jeep                81500 non-null uint8\n",
      "Maker_kia                 81500 non-null uint8\n",
      "Maker_lamborghini         81500 non-null uint8\n",
      "Maker_lancia              81500 non-null uint8\n",
      "Maker_land-rover          81500 non-null uint8\n",
      "Maker_lexus               81500 non-null uint8\n",
      "Maker_lotus               81500 non-null uint8\n",
      "Maker_maserati            81500 non-null uint8\n",
      "Maker_mazda               81500 non-null uint8\n",
      "Maker_mercedes-benz       81500 non-null uint8\n",
      "Maker_mini                81500 non-null uint8\n",
      "Maker_mitsubishi          81500 non-null uint8\n",
      "Maker_nissan              81500 non-null uint8\n",
      "Maker_opel                81500 non-null uint8\n",
      "Maker_peugeot             81500 non-null uint8\n",
      "Maker_porsche             81500 non-null uint8\n",
      "Maker_renault             81500 non-null uint8\n",
      "Maker_rolls-royce         81500 non-null uint8\n",
      "Maker_rover               81500 non-null uint8\n",
      "Maker_seat                81500 non-null uint8\n",
      "Maker_skoda               81500 non-null uint8\n",
      "Maker_smart               81500 non-null uint8\n",
      "Maker_subaru              81500 non-null uint8\n",
      "Maker_suzuki              81500 non-null uint8\n",
      "Maker_tesla               81500 non-null uint8\n",
      "Maker_toyota              81500 non-null uint8\n",
      "Maker_volkswagen          81500 non-null uint8\n",
      "Maker_volvo               81500 non-null uint8\n",
      "Body type_compact         81500 non-null uint8\n",
      "Body type_convertible     81500 non-null uint8\n",
      "Body type_coupe           81500 non-null uint8\n",
      "Body type_offroad         81500 non-null uint8\n",
      "Body type_other           81500 non-null uint8\n",
      "Body type_sedan           81500 non-null uint8\n",
      "Body type_stationwagon    81500 non-null uint8\n",
      "Body type_transporter     81500 non-null uint8\n",
      "Body type_van             81500 non-null uint8\n",
      "Color_beige               81500 non-null uint8\n",
      "Color_black               81500 non-null uint8\n",
      "Color_blue                81500 non-null uint8\n",
      "Color_bronze              81500 non-null uint8\n",
      "Color_brown               81500 non-null uint8\n",
      "Color_gold                81500 non-null uint8\n",
      "Color_green               81500 non-null uint8\n",
      "Color_grey                81500 non-null uint8\n",
      "Color_orange              81500 non-null uint8\n",
      "Color_red                 81500 non-null uint8\n",
      "Color_silver              81500 non-null uint8\n",
      "Color_violet              81500 non-null uint8\n",
      "Color_white               81500 non-null uint8\n",
      "Color_yellow              81500 non-null uint8\n",
      "Fuel_cng                  81500 non-null uint8\n",
      "Fuel_diesel               81500 non-null uint8\n",
      "Fuel_electric             81500 non-null uint8\n",
      "Fuel_gasoline             81500 non-null uint8\n",
      "Fuel_lpg                  81500 non-null uint8\n",
      "manual                    81500 non-null int32\n",
      "dtypes: float64(4), int32(4), uint8(74)\n",
      "memory usage: 10.1 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing mileage to a binary of milage over 100K Kilometers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['mileage_100K'] = df['mileage'] > 100000\n",
    "\n",
    "# we want to predict the X and y data as follows:\n",
    "\n",
    "y = df['mileage_100K'].values # get the labels we want\n",
    "del df['mileage_100K'] \n",
    "del df['mileage']# get rid of the class label\n",
    "X = df.values # use everything else to predict!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation part 2 - Final dataset.\n",
    "The final dataset constists of 81500 records with 82 columns.\n",
    "\n",
    "First we downloaded our dataset of car sales in the Czech Republic and Germany.  Most of it downloads as obect type so we changed door count and seat count to intergers.  \n",
    "\n",
    "We calculated the difference between when the advertisment started and was dropped and created a new variable of total days the ad ran.    \n",
    "\n",
    "We dropped the stk-year and model, stk-year is not needed since it is very similar to model year.  Model has to many classifications in the rows for us to be able to seperate it out.  When we tried we ran out of memory.\n",
    "\n",
    "Speaking of seperation the classifactions out, we spereated out Maker, Body type, Color, and Fuel type with one hot endoing. \n",
    "\n",
    "We also, dropped any row with a NA value.  This was done for two reasons, first it removed useless rows that will mess with our classifiaction models, second since we started with 3.5M records dropping the rows with NAs left us with 81500 rows of usable data.  The entire 3.5M records would eat up the resources of our machines and 81500 records should be a large enough sampleset to properly capture the nature of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Model and Evaluation 1 - Evaluation Metric.\n",
    "\n",
    "\n",
    "**********Needs to be written better****\n",
    "\n",
    "I think we should focus on accuarcy.  We are not worried if ther are false positives or false negatives.  F-measurements could be used, but we will use somethign like that ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model and Evaluation 2 - dividing data\n",
    "\n",
    "\n",
    "****Needs to be written up\n",
    "I say we do 10 fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "cv = StratifiedKFold(n_splits=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model and Evaluation 3 - Model selection\n",
    "\n",
    "** Needs write up\n",
    "I say we do K nearest neighbors, random forest, and Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest  1  accuracy 0.427922954239\n",
      "Random Forest  2  accuracy 0.854864433812\n",
      "Random Forest  3  accuracy 0.873267083793\n",
      "Random Forest  4  accuracy 0.84713532082\n",
      "Random Forest  5  accuracy 0.846993865031\n",
      "Random Forest  6  accuracy 0.794969325153\n",
      "Random Forest  7  accuracy 0.7728555651\n",
      "Random Forest  8  accuracy 0.74438581421\n",
      "Random Forest  9  accuracy 0.801570744877\n",
      "Random Forest  10  accuracy 0.746349245306\n",
      "Average accuracy =  80.2874064341 +- 4.72652842162\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=50,random_state=1)\n",
    "iter_num = 1\n",
    "rf_acc=acc\n",
    "\n",
    "for train_indices, test_indices in cv.split(X,y): \n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    clf.fit(X_train,y_train) \n",
    "    y_hat = clf.predict(X_test)\n",
    "    rf_acc[inter_num] = mt.accuracy_score(y_test,y_hat)\n",
    "    print(\"Random Forest \", iter_num,\" accuracy\", rf_acc[inter_num] )\n",
    "    iter_num+=1\n",
    "    \n",
    "print (\"Average accuracy = \", rf_acc.mean()*100, \"+-\", rf_acc.std()*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-6c21023ea524>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_indices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0my_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mknn_acc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minter_num\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_hat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"K Nearest Neighbors \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miter_num\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\" accuracy\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mknn_acc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minter_num\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\neighbors\\classification.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0mneigh_dist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneigh_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\neighbors\\base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    379\u001b[0m                 delayed(self._tree.query, check_pickle=False)(\n\u001b[1;32m    380\u001b[0m                     X[s], n_neighbors, return_distance)\n\u001b[0;32m--> 381\u001b[0;31m                 \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgen_even_slices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m             )\n\u001b[1;32m    383\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    606\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics as mt\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors=3)\n",
    "iter_num = 1\n",
    "knn_acc=acc\n",
    "\n",
    "for train_indices, test_indices in cv.split(X,y): \n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    clf.fit(X_train,y_train) \n",
    "    y_hat = clf.predict(X_test)\n",
    "    knn_acc[inter_num] = mt.accuracy_score(y_test,y_hat)\n",
    "    print(\"K Nearest Neighbors \", iter_num,\" accuracy\", knn_acc[inter_num] )\n",
    "    iter_num+=1\n",
    "    \n",
    "print (\"Average accuracy = \", knn_acc.mean()*100, \"+-\", knn_acc.std()*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_clf = LogisticRegression() # get object\n",
    "iter_num=0\n",
    "lr_acc=acc\n",
    "\n",
    "for train_indices, test_indices in cv_object.split(X,y): \n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    lr_clf.fit(X_train,y_train) \n",
    "    y_hat = lr_clf.predict(X_test)\n",
    "    lr_acc = mt.accuracy_score(y_test,y_hat)\n",
    "    print(\"Logistic Regression \", iter_num,\" accuracy\", lr_acc )\n",
    "    iter_num+=1\n",
    "    \n",
    "print (\"Average accuracy = \", lr_acc.mean()*100, \"+-\", lr_acc.std()*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling and Evaluation 4 - Analyze Results\n",
    "\n",
    "Need write up and visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling and Evaluation 5 - Model advantages\n",
    "\n",
    "Need write up\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling and Evaluation 6 - Important attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
